importing the dataset...
Loading train.json
Loading test.json
Small dataset version, not loading support.json
Loading dev.json
Finished
Loading labels...   Finished
Loading user description embeddings
Finished
Running tweet embedding
Finished
Processing feature3...   Finished
Processing feature4...   Finished
Building graph   Finished
Traceback (most recent call last):
  File "trainTestHetero.py", line 60, in <module>
    wandb.watch(model)
  File "/usr/local/anaconda3/envs/mlp/lib/python3.7/site-packages/wandb/sdk/wandb_watch.py", line 96, in watch
    log_freq=log_freq,
  File "/usr/local/anaconda3/envs/mlp/lib/python3.7/site-packages/wandb/wandb_torch.py", line 126, in add_log_hooks_to_pytorch_module
    parameter, "gradients/" + prefix + name, log_track_grad
  File "/usr/local/anaconda3/envs/mlp/lib/python3.7/site-packages/wandb/wandb_torch.py", line 264, in _hook_variable_gradient_stats
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
  File "/usr/local/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/_tensor.py", line 339, in register_hook
    return handle_torch_function(Tensor.register_hook, (self,), self, hook)
  File "/usr/local/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/overrides.py", line 1355, in handle_torch_function
    result = torch_func_method(public_api, types, args, kwargs)
  File "/usr/local/anaconda3/envs/mlp/lib/python3.7/site-packages/torch/nn/parameter.py", line 126, in __torch_function__
    'to initialize the parameters before calling torch functions'.format(func, cls.__name__))
ValueError: Attempted to use an uninitialized parameter in <function Tensor.register_hook at 0x7fd26833e3b0>. This error happens when you are using a `LazyModule` or explicitly manipulating `torch.nn.parameter.UninitializedParameter` objects. When using LazyModules Call `forward` with a dummy batch to initialize the parameters before calling torch functions