{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded df_dev\n",
      "df_dev shape (2365, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_dev = pd.read_json('./Twibot-20/dev.json')\n",
    "\n",
    "print('loaded df_dev')\n",
    "print('df_dev shape', df_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "example_tweet = \"RT @andersoncooper Today on @Anderson @PAAK: the debate over #ADHD -- are kids being overmedicated? #Thursday #Anderson\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['andersoncooper']\n",
      "['Anderson', 'PAAK']\n"
     ]
    }
   ],
   "source": [
    "retweetUnameRegex = re.compile(r'(?<=RT @)(\\w{1,15})')\n",
    "mentionsUnameRegex = re.compile(r'(?<!RT @)(?<=@)(\\w{1,15})')\n",
    "# retweetUnameRegex.search(example_tweet)\n",
    "print(retweetUnameRegex.findall(example_tweet))\n",
    "print(mentionsUnameRegex.findall(example_tweet))\n",
    "# find = re.search(r'(?<=RT @)(\\w){1,15}', example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# extracting tweets dataframe from df_dev\n",
    "# each tweet has a body (text), id (T-userID-tweetNumberByUser), and neighbours - can extract neighbourhoods from userID as well as RT @uname/ @uname for mentions.\n",
    "## REGULAR EXPRESSIONS\n",
    "# Regex for capturing Retweet uname: (?<=RT @)(\\w{1,15})\n",
    "# Regex for Mention unames (All inclusive): (?<=@)(\\w{1,15})\n",
    "# Regex for Mention unames WITHOUT retweets: (?<!RT @)(?<=@)(\\w{1,15})\n",
    "\n",
    "# will extract the 3 different sets of neighbours separately then the different version of the dataset can use these freely.\n",
    "import re\n",
    "\n",
    "\n",
    "def extractNeighborUnameDict(tweet):\n",
    "    # extract retweet uname\n",
    "\n",
    "    retweet_uname = re.findall(r'(?<=RT @)(\\w{1,15})', tweet)\n",
    "\n",
    "    # extract mention unames without retweets\n",
    "    mentions_no_rt = re.findall(r'(?<!RT @)(?<=@)(\\w{1,15})', tweet)\n",
    "\n",
    "    return {\"retweeted\": retweet_uname, \"mentions\": mentions_no_rt}\n",
    "\n",
    "df_tweet = df_dev[df_dev.tweet.notnull()].apply(lambda x: pd.Series([{\"ID\": \"T\"+ str(x['ID']) + \"-\" + str(i), \"Body\": tweet, \"neighborUsernames\": extractNeighborUnameDict(tweet), \"tweeterId\": x['ID']} for (i,tweet) in enumerate(x['tweet'])]), axis=1)\n",
    "\n",
    "print(type(df_tweet))\n",
    "# print(df_tweet[:5])\n",
    "# unameDict = extractNeighborUnameDict(example_tweet)\n",
    "# print(unameDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=200, step=1)\n",
      "(2350, 200)\n",
      "(5, 200)\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet.columns)\n",
    "print(df_tweet.shape)\n",
    "\n",
    "print(df_tweet.head().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0      {'ID': 'T1224667050301255680-0', 'Body': '@Spa...\n",
      "      1      {'ID': 'T1224667050301255680-1', 'Body': '@Bar...\n",
      "      2      {'ID': 'T1224667050301255680-2', 'Body': 'সেদি...\n",
      "      3      {'ID': 'T1224667050301255680-3', 'Body': 'নিজে...\n",
      "      4      {'ID': 'T1224667050301255680-4', 'Body': 'ফোন ...\n",
      "                                   ...                        \n",
      "2364  195    {'ID': 'T412642667-195', 'Body': 'RT @JaylaCym...\n",
      "      196    {'ID': 'T412642667-196', 'Body': 'RT @WWE: The...\n",
      "      197    {'ID': 'T412642667-197', 'Body': 'Cooking, Cla...\n",
      "      198    {'ID': 'T412642667-198', 'Body': 'RT @TheYBF: ...\n",
      "      199    {'ID': 'T412642667-199', 'Body': 'RT @TheYBF: ...\n",
      "Length: 401525, dtype: object\n",
      "(401525,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet.stack())\n",
    "print(df_tweet.stack().shape)\n",
    "print(type(df_tweet.stack()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401525, 4)\n"
     ]
    }
   ],
   "source": [
    "df_tweet_alt = pd.DataFrame(list(df_tweet.stack()))\n",
    "print(df_tweet_alt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Body', 'neighborUsernames', 'tweeterId'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet_alt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final code for extracting the tweets dataframe from df_dev\n",
    "\n",
    "df_tweet = df_dev[df_dev.tweet.notnull()].apply(lambda x: pd.Series([{\"ID\": \"T\"+ str(x['ID']) + \"-\" + str(i), \"Body\": tweet, **extractNeighborUnameDict(tweet), \"tweeterId\": x['ID']} for (i,tweet) in enumerate(x['tweet'])]), axis=1)\n",
    "stacked_df_tweet = df_tweet.stack()\n",
    "df_tweet = pd.DataFrame(list(stacked_df_tweet), index=pd.RangeIndex(df_dev.shape[0], stacked_df_tweet.shape[0] + df_dev.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Body', 'retweeted', 'mentions', 'tweeterId'], dtype='object')\n",
      "(401525, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet.columns)\n",
    "print(df_tweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_dict = df_tweet.transpose().to_dict()\n",
    "\n",
    "# for index,tweet in df_tweet_dict.items():\n",
    "#     print(index)\n",
    "#     print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 'T1224667050301255680-0', 'Body': '@SparklesOnlyme পুরোনো এইদিনের কথা\\n', 'retweeted': [], 'mentions': ['SparklesOnlyme'], 'tweeterId': 1224667050301255680}\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet_dict[2365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401525, 6)\n",
      "Index(['ID', 'Body', 'retweeted', 'mentions', 'tweeterId', 'rowIndex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_tweet['rowIndex'] = df_tweet.index\n",
    "print(df_tweet.shape)\n",
    "print(df_tweet.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'profile', 'neighbor', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Attempting to concatenate to df_dev (without the tweets column now)\n",
    "# df_dev = df_dev.iloc[:, [0,1,3,5]]\n",
    "# print(df_dev.columns)\n",
    "df_dev_no_tweets = df_dev.iloc[:, [0,1,3,5]]\n",
    "\n",
    "print(df_dev_no_tweets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_keep_index = pd.concat([df_dev_no_tweets, df_tweet], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'profile', 'neighbor', 'label', 'ID', 'Body', 'retweeted',\n",
      "       'mentions', 'tweeterId'],\n",
      "      dtype='object')\n",
      "(403890, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(concat_keep_index.columns)\n",
    "\n",
    "\n",
    "print(concat_keep_index.shape)\n",
    "\n",
    "# actually, let's NOT concatenate the tweets dataframe to the users dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'id_str', 'name', 'screen_name', 'location', 'profile_location',\n",
      "       'description', 'url', 'entities', 'protected', 'followers_count',\n",
      "       'friends_count', 'listed_count', 'created_at', 'favourites_count',\n",
      "       'utc_offset', 'time_zone', 'geo_enabled', 'verified', 'statuses_count',\n",
      "       'lang', 'contributors_enabled', 'is_translator',\n",
      "       'is_translation_enabled', 'profile_background_color',\n",
      "       'profile_background_image_url', 'profile_background_image_url_https',\n",
      "       'profile_background_tile', 'profile_image_url',\n",
      "       'profile_image_url_https', 'profile_link_color',\n",
      "       'profile_sidebar_border_color', 'profile_sidebar_fill_color',\n",
      "       'profile_text_color', 'profile_use_background_image',\n",
      "       'has_extended_profile', 'default_profile', 'default_profile_image'],\n",
      "      dtype='object')\n",
      "0     sunnyhowlader5\n",
      "1      Maebha_Racing\n",
      "2    thepennyhoarder\n",
      "3           momlogic\n",
      "4            Variety\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_dev_profiles = df_dev[df_dev.profile.notnull()].apply(lambda x: pd.Series(x.profile), axis=1)\n",
    "# print(type(df_dev_profiles))\n",
    "# print(df_dev_profiles.shape)\n",
    "# print(df_dev_profiles.head())\n",
    "print(df_dev_profiles.columns)\n",
    "\n",
    "screen_names = df_dev_profiles.apply(lambda x: x.screen_name.strip(), axis=1)\n",
    "print(screen_names.head())\n",
    "\n",
    "# profile_df = pd.DataFrame(df_dev_with_profiles['profile'])\n",
    "# print(profile_df.shape)\n",
    "# print(profile_df.columns)\n",
    "# print(pd.Series(df_dev_with_profiles.head()['profile']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensionality of uname2id dict 2365\n"
     ]
    }
   ],
   "source": [
    "df_dev_profiles = df_dev[df_dev.profile.notnull()].apply(lambda x: pd.Series(x.profile), axis=1)\n",
    "uname2id_dict = {x['screen_name'].strip(): x['id'].strip() for index, x in df_dev_profiles.iloc[:,[3,0]].transpose().to_dict().items()}\n",
    "# uname2id_dict = {user['profile']['screen_name'].strip():user['ID'] for user in df_dev[df_dev.profile.notnull()][df_dev.profile['screen_name'] is not None]}\n",
    "print('dimensionality of uname2id dict', len(uname2id_dict))\n",
    "# print(uname2id_dict)\n",
    "# print(uname2id_dict)\n",
    "# print('sample from uname2id dict', uname2id_dict['realDonaldTrump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1cb601c7a98d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTwibotSmallAugmentedTSVDHomogeneous\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwibotSmallAugmentedTSVDHomogeneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhomogeneous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwibotSmallAugmentedTSVDHomogeneous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdes_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweets_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhomogeneous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EdiStuff/Dissertation/Code/BotRGCN-Adapted/TwibotSmallAugmentedTSVDHomogeneous.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, device, process, save, dev, svdComponents)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'cpu'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvdComponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvdComponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "from TwibotSmallAugmentedTSVDHomogeneous import TwibotSmallAugmentedTSVDHomogeneous\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "homogeneous = TwibotSmallAugmentedTSVDHomogeneous(dev=False, device=device)\n",
    "\n",
    "des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type,labels,train_idx,val_idx,test_idx=homogeneous.dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76293e17429ae2c839469a84a4692f69b1d764ad81a6a044a99c52430bb10e84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
