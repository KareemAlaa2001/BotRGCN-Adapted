{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded df_dev\n",
      "df_dev shape (2365, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_dev = pd.read_json('./Twibot-20/dev.json')\n",
    "\n",
    "print('loaded df_dev')\n",
    "print('df_dev shape', df_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "example_tweet = \"RT @andersoncooper Today on @Anderson @PAAK: the debate over #ADHD -- are kids being overmedicated? #Thursday #Anderson\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['andersoncooper']\n",
      "['Anderson', 'PAAK']\n"
     ]
    }
   ],
   "source": [
    "retweetUnameRegex = re.compile(r'(?<=RT @)(\\w{1,15})')\n",
    "mentionsUnameRegex = re.compile(r'(?<!RT @)(?<=@)(\\w{1,15})')\n",
    "# retweetUnameRegex.search(example_tweet)\n",
    "print(retweetUnameRegex.findall(example_tweet))\n",
    "print(mentionsUnameRegex.findall(example_tweet))\n",
    "# find = re.search(r'(?<=RT @)(\\w){1,15}', example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# extracting tweets dataframe from df_dev\n",
    "# each tweet has a body (text), id (T-userID-tweetNumberByUser), and neighbours - can extract neighbourhoods from userID as well as RT @uname/ @uname for mentions.\n",
    "## REGULAR EXPRESSIONS\n",
    "# Regex for capturing Retweet uname: (?<=RT @)(\\w{1,15})\n",
    "# Regex for Mention unames (All inclusive): (?<=@)(\\w{1,15})\n",
    "# Regex for Mention unames WITHOUT retweets: (?<!RT @)(?<=@)(\\w{1,15})\n",
    "\n",
    "# will extract the 3 different sets of neighbours separately then the different version of the dataset can use these freely.\n",
    "import re\n",
    "\n",
    "\n",
    "def extractNeighborUnameDict(tweet):\n",
    "    # extract retweet uname\n",
    "\n",
    "    retweet_uname = re.findall(r'(?<=RT @)(\\w{1,15})', tweet)\n",
    "\n",
    "    # extract mention unames without retweets\n",
    "    mentions_no_rt = re.findall(r'(?<!RT @)(?<=@)(\\w{1,15})', tweet)\n",
    "\n",
    "    return {\"retweeted\": retweet_uname, \"mentions\": mentions_no_rt}\n",
    "\n",
    "\n",
    "df_tweet = df_dev[df_dev.tweet.notnull()].apply(lambda x: pd.Series([{\"ID\": \"T\"+ str(x['ID']) + \"-\" + str(i), \"Body\": tweet, \"neighborUsernames\": extractNeighborUnameDict(tweet), \"tweeterId\": x['ID']} for (i,tweet) in enumerate(x['tweet'])]), axis=1)\n",
    "\n",
    "print(type(df_tweet))\n",
    "# print(df_tweet[:5])\n",
    "# unameDict = extractNeighborUnameDict(example_tweet)\n",
    "# print(unameDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=200, step=1)\n",
      "(2350, 200)\n",
      "(5, 200)\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet.columns)\n",
    "print(df_tweet.shape)\n",
    "\n",
    "print(df_tweet.head().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0      {'ID': 'T1224667050301255680-0', 'Body': '@Spa...\n",
      "      1      {'ID': 'T1224667050301255680-1', 'Body': '@Bar...\n",
      "      2      {'ID': 'T1224667050301255680-2', 'Body': 'সেদি...\n",
      "      3      {'ID': 'T1224667050301255680-3', 'Body': 'নিজে...\n",
      "      4      {'ID': 'T1224667050301255680-4', 'Body': 'ফোন ...\n",
      "                                   ...                        \n",
      "2364  195    {'ID': 'T412642667-195', 'Body': 'RT @JaylaCym...\n",
      "      196    {'ID': 'T412642667-196', 'Body': 'RT @WWE: The...\n",
      "      197    {'ID': 'T412642667-197', 'Body': 'Cooking, Cla...\n",
      "      198    {'ID': 'T412642667-198', 'Body': 'RT @TheYBF: ...\n",
      "      199    {'ID': 'T412642667-199', 'Body': 'RT @TheYBF: ...\n",
      "Length: 401525, dtype: object\n",
      "(401525,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet.stack())\n",
    "print(df_tweet.stack().shape)\n",
    "print(type(df_tweet.stack()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401525, 4)\n"
     ]
    }
   ],
   "source": [
    "df_tweet_alt = pd.DataFrame(list(df_tweet.stack()))\n",
    "print(df_tweet_alt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Body', 'neighborUsernames', 'tweeterId'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet_alt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final code for extracting the tweets dataframe from df_dev\n",
    "\n",
    "df_tweet = df_dev[df_dev.tweet.notnull()].apply(lambda x: pd.Series([{\"ID\": \"T\"+ str(x['ID']) + \"-\" + str(i), \"Body\": tweet, **extractNeighborUnameDict(tweet), \"tweeterId\": x['ID']} for (i,tweet) in enumerate(x['tweet'])]), axis=1)\n",
    "stacked_df_tweet = df_tweet.stack()\n",
    "df_tweet = pd.DataFrame(list(stacked_df_tweet), index=pd.RangeIndex(df_dev.shape[0], stacked_df_tweet.shape[0] + df_dev.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Body', 'retweeted', 'mentions', 'tweeterId'], dtype='object')\n",
      "(401525, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet.columns)\n",
    "print(df_tweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_dict = df_tweet.transpose().to_dict()\n",
    "\n",
    "# for index,tweet in df_tweet_dict.items():\n",
    "#     print(index)\n",
    "#     print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 'T1224667050301255680-0', 'Body': '@SparklesOnlyme পুরোনো এইদিনের কথা\\n', 'retweeted': [], 'mentions': ['SparklesOnlyme'], 'tweeterId': 1224667050301255680}\n"
     ]
    }
   ],
   "source": [
    "print(df_tweet_dict[2365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401525, 6)\n",
      "Index(['ID', 'Body', 'retweeted', 'mentions', 'tweeterId', 'rowIndex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_tweet['rowIndex'] = df_tweet.index\n",
    "print(df_tweet.shape)\n",
    "print(df_tweet.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'profile', 'neighbor', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Attempting to concatenate to df_dev (without the tweets column now)\n",
    "# df_dev = df_dev.iloc[:, [0,1,3,5]]\n",
    "# print(df_dev.columns)\n",
    "df_dev_no_tweets = df_dev.iloc[:, [0,1,3,5]]\n",
    "\n",
    "print(df_dev_no_tweets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_keep_index = pd.concat([df_dev_no_tweets, df_tweet], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'profile', 'neighbor', 'label', 'ID', 'Body', 'retweeted',\n",
      "       'mentions', 'tweeterId'],\n",
      "      dtype='object')\n",
      "(403890, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(concat_keep_index.columns)\n",
    "\n",
    "\n",
    "print(concat_keep_index.shape)\n",
    "\n",
    "# actually, let's NOT concatenate the tweets dataframe to the users dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'id_str', 'name', 'screen_name', 'location', 'profile_location',\n",
      "       'description', 'url', 'entities', 'protected', 'followers_count',\n",
      "       'friends_count', 'listed_count', 'created_at', 'favourites_count',\n",
      "       'utc_offset', 'time_zone', 'geo_enabled', 'verified', 'statuses_count',\n",
      "       'lang', 'contributors_enabled', 'is_translator',\n",
      "       'is_translation_enabled', 'profile_background_color',\n",
      "       'profile_background_image_url', 'profile_background_image_url_https',\n",
      "       'profile_background_tile', 'profile_image_url',\n",
      "       'profile_image_url_https', 'profile_link_color',\n",
      "       'profile_sidebar_border_color', 'profile_sidebar_fill_color',\n",
      "       'profile_text_color', 'profile_use_background_image',\n",
      "       'has_extended_profile', 'default_profile', 'default_profile_image'],\n",
      "      dtype='object')\n",
      "0     sunnyhowlader5\n",
      "1      Maebha_Racing\n",
      "2    thepennyhoarder\n",
      "3           momlogic\n",
      "4            Variety\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_dev_profiles = df_dev[df_dev.profile.notnull()].apply(lambda x: pd.Series(x.profile), axis=1)\n",
    "# print(type(df_dev_profiles))\n",
    "# print(df_dev_profiles.shape)\n",
    "# print(df_dev_profiles.head())\n",
    "print(df_dev_profiles.columns)\n",
    "\n",
    "screen_names = df_dev_profiles.apply(lambda x: x.screen_name.strip(), axis=1)\n",
    "print(screen_names.head())\n",
    "\n",
    "# profile_df = pd.DataFrame(df_dev_with_profiles['profile'])\n",
    "# print(profile_df.shape)\n",
    "# print(profile_df.columns)\n",
    "# print(pd.Series(df_dev_with_profiles.head()['profile']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensionality of uname2id dict 2365\n"
     ]
    }
   ],
   "source": [
    "df_dev_profiles = df_dev[df_dev.profile.notnull()].apply(lambda x: pd.Series(x.profile), axis=1)\n",
    "uname2id_dict = {x['screen_name'].strip(): x['id'].strip() for index, x in df_dev_profiles.iloc[:,[3,0]].transpose().to_dict().items()}\n",
    "# uname2id_dict = {user['profile']['screen_name'].strip():user['ID'] for user in df_dev[df_dev.profile.notnull()][df_dev.profile['screen_name'] is not None]}\n",
    "print('dimensionality of uname2id dict', len(uname2id_dict))\n",
    "# print(uname2id_dict)\n",
    "# print(uname2id_dict)\n",
    "# print('sample from uname2id dict', uname2id_dict['realDonaldTrump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.json\n",
      "Loading test.json\n",
      "Small dataset version, not loading support.json\n",
      "Loading dev.json\n",
      "Finished\n",
      "extracting df_tweet\n",
      "Loading labels...   Finished\n",
      "Loading user description embeddings\n",
      "Finished\n",
      "Running tweet embedding\n",
      "Finished\n",
      "Processing feature3...   Finished\n",
      "Processing feature4...   Finished\n",
      "Building graph   Finished\n"
     ]
    }
   ],
   "source": [
    "from TwibotSmallAugmentedTSVDHomogeneous import TwibotSmallAugmentedTSVDHomogeneous\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "homogeneous = TwibotSmallAugmentedTSVDHomogeneous(dev=False, device=device)\n",
    "\n",
    "des_tensor,tweets_tensor,num_prop,category_prop,edge_index,edge_type,labels,train_idx,val_idx,test_idx=homogeneous.dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2)\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "[[3. 4.]\n",
      " [5. 6.]]\n",
      "[4 5]\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "conf_mat = np.array([[1,2],[3,4]])\n",
    "second_conf_mat = np.array([[5,6],[7,8]])\n",
    "\n",
    "conf_mat_list = [conf_mat, second_conf_mat]\n",
    "\n",
    "print(np.array(conf_mat_list).shape)\n",
    "print(np.array(conf_mat_list))\n",
    "print(np.array(conf_mat_list).mean(axis=0))\n",
    "print(np.array([np.array(4), np.array(5)]))\n",
    "print(np.array([1,2,3,4]).mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76293e17429ae2c839469a84a4692f69b1d764ad81a6a044a99c52430bb10e84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
